# **Анализ задачи**

## Что было сделано

Для автоматизации сбора цитат с веб-сайта Quotes to Scrape была разработана программа на Python с использованием библиотеки Selenium WebDriver. Основные этапы работы включали:

1. Инициализацию Chrome WebDriver с использованием webdriver_manager, чтобы обеспечить совместимость между версиями браузера Chrome и ChromeDriver.
2. Запуск веб-драйвера и открытие стартовой страницы сайта.
3. Сбор цитат, авторов и тегов со страницы.
4. Навигацию на следующую страницу сайта для последовательного сбора всех цитат.
5. Выгрузку данных для дальнейшего анализа.


## Откуда были получены данные

Данные были получены с веб-сайта Quotes to Scrape. На этом сайте представлена коллекция цитат с их авторами и тематическими тегами. Данные собирались из HTML-кода каждой страницы, а именно из элементов с атрибутами, относящимися к цитатам, авторам и тегам.

## Как осуществлялся сбор

Для извлечения информации о цитатах использовались XPath и CSS-селекторы для элементов, содержащих:
* Текст цитаты.
* Имя автора.
* Список тегов.

Скрипт был настроен на переход к следующей странице с помощью кнопки "Next". Цикл продолжался до тех пор, пока все страницы не были пройдены, и на каждой из них данные сохранялись в структурированном формате.

## Почему был выбран тот или иной метод/инструмент

1. ### Selenium WebDriver:

* Selenium WebDriver был выбран для автоматизированного взаимодействия с веб-страницей, так как он предоставляет гибкий и простой в использовании интерфейс для веб-скрапинга динамических страниц.
* В отличие от BeautifulSoup, который предназначен для парсинга HTML, Selenium позволяет имитировать поведение пользователя, что полезно при навигации между страницами с помощью кнопок.
2. ### WebDriver Manager:

* webdriver_manager был использован для автоматического обновления и установки версии ChromeDriver, соответствующей текущей версии браузера. Это значительно упростило настройку, устранив потенциальные проблемы несовместимости.
3. ### XPath и CSS-селекторы:

* XPath и CSS-селекторы были выбраны для точного нахождения нужных элементов на странице. XPath позволяет легко указать элементы, основанные на их структуре и атрибутах, что полезно для навигации по сложным иерархиям HTML.

